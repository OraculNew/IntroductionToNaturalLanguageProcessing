{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN7W46PYfq0P"
      },
      "source": [
        "# Введение в обработку естественного языка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6GaBdpZfq0Q"
      },
      "source": [
        "В данном мини-проекте я попробую создать чат-бота с нуля.\n",
        "\n",
        "Бот в телеграме: @Nlp_course_2022_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kZFifQG0fq0R"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import nltk\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import LinearSVC\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AZOjjlUvfq0R"
      },
      "outputs": [],
      "source": [
        "BOT_CONFIG = {\n",
        "    'intents': {\n",
        "        'hello': {\n",
        "            'examples': ['Привет','Добрый день','Привет, бот', 'нихао'],\n",
        "            'responses': ['Привет, человек','И вам здравствуйте', 'Доброго времени суток']\n",
        "        },\n",
        "        \n",
        "        'bye': {\n",
        "             'examples': ['Пока', 'До свидания', 'Досвидания', 'До скорой встречи'],\n",
        "            'responses': ['Еще увидимся', 'Если что, я всегда тут']\n",
        "        },\n",
        "        \n",
        "        'name': {\n",
        "             'examples': ['Как тебя зовут?', 'Представься', 'У тебя есть имя?'],\n",
        "            'responses': ['Меня зовут Федя']\n",
        "        },\n",
        "    },\n",
        "   \n",
        "    'failure_phrases': [\n",
        "        'Непонятно. Перефразируйте, пожалуйста',\n",
        "        'Я еще только учусь. Спросите что-нибудь другое',\n",
        "        'Слишком сложный вопрос для меня'\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7GPGQnXfq0S",
        "outputId": "0b70eb64-f16f-4a45-dbe0-d68b803715e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#разделение выборки на интенты и классы\n",
        "X_text = []\n",
        "y = []\n",
        " \n",
        "for intent, intent_data in BOT_CONFIG['intents'].items():\n",
        "    for example in intent_data['examples']:\n",
        "        X_text.append(example)\n",
        "        y.append(intent)\n",
        "        \n",
        "# векторизация\n",
        "vectorizer = TfidfVectorizer(analyzer = 'char', ngram_range = (3,3))\n",
        "\n",
        "X = vectorizer.fit_transform(X_text)\n",
        "\n",
        "# ML\n",
        "clf = LinearSVC()\n",
        "clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "B_FyeUZ6fq0S"
      },
      "outputs": [],
      "source": [
        "# очистка текста от лишних символов и знаков препинания\n",
        "def clean(text):\n",
        "    clean_text = ''\n",
        "    for ch in text.lower():\n",
        "        if ch in 'абвгдеёжзийклмнопрстуфхцчшщъыьэюя ':\n",
        "            clean_text += ch\n",
        "    # с помощью .strip() уберем лишние пробелы в начале и в конце фразы\n",
        "    return clean_text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Kap848ICfq0T",
        "outputId": "80884cc3-bc85-4d73-adab-9086e815a84a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'name'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "def classify_intent(replica):\n",
        "    replica = clean(replica)\n",
        "    intent = clf.predict(vectorizer.transform([replica]))[0]\n",
        "    \n",
        "    for example in BOT_CONFIG['intents'][intent]['examples']:\n",
        "        for example in intent_data['examples']:\n",
        "            example = clean(example)\n",
        "            #научимся работать с мелкими ошибками с помощью расстояния Левенштейна\n",
        "            distance = nltk.edit_distance(replica, example)\n",
        "            if distance / len(example) <= 0.5:\n",
        "                return intent\n",
        "classify_intent('как тебя зовут?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "BJwrGEuhfq0T",
        "outputId": "b77b7644-ca8f-4059-a2a2-a0590d9d3288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2411\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Мальчик, Точно.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "def get_answer_by_intent(intent):\n",
        "      for intent in BOT_CONFIG['intents']:\n",
        "            responses = BOT_CONFIG['intents'][intent]['responses']\n",
        "            return random.choice(responses)\n",
        "        \n",
        "# в качестве корпуса текстов возьмем корпус из \n",
        "# https://github.com/Koziev/NLP_Datasets/blob/master/Conversations/Data/dialogues.zip\n",
        "\n",
        "with open('/content/dialogues.txt', encoding=\"utf8\") as f:\n",
        "    content = f.read()\n",
        "    \n",
        "content[:1000]\n",
        "\n",
        "# запишем каждый диалог с новой строки и отделим фразы \\n\\n\n",
        "dialogues_str = content.split('\\n\\n')\n",
        "# уберем лишнюю \\n, оставим в диалоге только 2 фразы и выведем результат\n",
        "dialogues = [dialogues_str.split('\\n')[:2] for dialogues_str in dialogues_str]\n",
        "\n",
        "dialogues_filtered = []\n",
        "\n",
        "# убрали дубликаты диалогов\n",
        "questions = set()\n",
        "\n",
        "for dialogue in dialogues:\n",
        "    if len(dialogue) != 2:\n",
        "        continue\n",
        "    \n",
        "    question, answer = dialogue\n",
        "    #убираем перевые два символа из фразы\n",
        "    question = clean(question[2:])\n",
        "    answer = answer[2:]\n",
        "    \n",
        "    if question != '' and question not in questions:\n",
        "        questions.add(question)\n",
        "        dialogues_filtered.append([question, answer])\n",
        "\n",
        "# структурируем вопросы по словам для повышения скорости вычислений\n",
        "dialogues_structured = {}\n",
        "\n",
        "for question, answer in dialogues_filtered:\n",
        "    words = question.split(' ')\n",
        "    \n",
        "    for word in words:\n",
        "        if word not in dialogues_structured:\n",
        "            dialogues_structured[word] = []\n",
        "        dialogues_structured[word].append([question, answer])\n",
        "\n",
        "# # у слишком частотных слов оставим только первую 1000 -> на каждую пару теперь приходится не более 1000 элементов\n",
        "dialogues_structured_cut = {}\n",
        "\n",
        "for word, pairs in dialogues_structured.items():\n",
        "    pairs.sort(key=lambda pair: len(pair[0]))\n",
        "    dialogues_structured_cut[word] = pairs[:1000]\n",
        "    \n",
        "# генерируем ответ    \n",
        "def generate_answer(replica):\n",
        "    \n",
        "    replica = clean(replica)\n",
        "    words = set(replica.split(' '))\n",
        "    \n",
        "    mini_dataset = []\n",
        "    for word in words:\n",
        "        if word in dialogues_structured:\n",
        "            mini_dataset += dialogues_structured_cut[word]     \n",
        "    \n",
        "    print(len(mini_dataset))\n",
        "    \n",
        "    answers = []\n",
        "    \n",
        "    for question, answer in mini_dataset:\n",
        "        # чтобы не считать расстоянение заведомо далеких фраз, отфильтруем их\n",
        "        abs(len(replica) - len(question)) < 0.2\n",
        "        #научимся работать с мелкими ошибками с помощью расстояния Левинштейна\n",
        "        distance = nltk.edit_distance(replica, question)\n",
        "        distance_weighted = distance / len(question)\n",
        "        if distance_weighted < 0.2:\n",
        "            answers.append([distance_weighted, question, answer])\n",
        "            \n",
        "        # из всех подходящих вариантов выберем не первый, а наиболее близкий по distance \n",
        "    if answers:\n",
        "        return min(answers, key=lambda three: three[0])[2]\n",
        "    \n",
        "#зададим вопрос боту            \n",
        "generate_answer('мальчик или девочка?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8aqmGn6Ofq0U"
      },
      "outputs": [],
      "source": [
        "def get_failure_phrase():\n",
        "    failure_phrases = [\n",
        "      \"Слишком ложно и непонятно, напиши чутка иначе\",\n",
        "      \"Я понял, что я не понял\",\n",
        "      \"что-то непонятно\",\n",
        "      \"Краткость - сестра таланта, скажите короче\",\n",
        "      \"Давай еще разочек\",\n",
        "      \"Пожалуйста, уточните\",\n",
        "      \"Не могли бы вы уточнить вопрос?\",\n",
        "    ]\n",
        "    return random.choice(failure_phrases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_k66AyCMfq0U"
      },
      "outputs": [],
      "source": [
        "# проверим статистику пути выбора ответа\n",
        "stats = {'intent': 0, 'generate': 0, 'failure': 0}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UkUSBGc8fq0U"
      },
      "outputs": [],
      "source": [
        "def bot(replica):\n",
        "    # NLU\n",
        "    intent = classify_intent(replica)\n",
        "    \n",
        "    # answer generation\n",
        "   \n",
        "    #выбор заготовленной реплики - ML\n",
        "    if intent:\n",
        "            answer = get_answer_by_intent(intent)\n",
        "            if answer:\n",
        "                stats['intent'] += 1\n",
        "                return answer\n",
        "    \n",
        "    # вызов генеративной модели\n",
        "    answer = generate_answer(replica)\n",
        "    if answer:\n",
        "        stats['generate'] += 1\n",
        "        return answer\n",
        "    \n",
        "    # берем заглушку\n",
        "    stats['failure'] += 1\n",
        "    return get_failure_phrase()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "0Xjjtclafq0U",
        "outputId": "39ec3606-dc92-4102-9b1d-52d3c0e4add8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "973\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Пожалуйста, уточните'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "bot('первый закон термодинамики')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHesrCjQfq0V",
        "outputId": "a7cb295d-90cf-46dc-feff-9acc17e2e271"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 0, 'generate': 0, 'failure': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apnsScxDfq0V",
        "outputId": "7c28132a-5d37-4bb6-9db3-722f29990e85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.7/dist-packages (13.13)\n",
            "Requirement already satisfied: cachetools==4.2.2 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (4.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2022.6.15)\n",
            "Requirement already satisfied: APScheduler==3.6.3 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (3.6.3)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (6.2)\n",
            "Requirement already satisfied: pytz>=2018.6 in /usr/local/lib/python3.7/dist-packages (from python-telegram-bot) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (57.4.0)\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.7/dist-packages (from APScheduler==3.6.3->python-telegram-bot) (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "# приступаем к настройке бота из https://github.com/python-telegram-bot/python-telegram-bot\n",
        "!pip install python-telegram-bot --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tornado\n",
        "tornado.version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "izCqOXg7mTrS",
        "outputId": "0d92099f-eac6-4e17-ae88-a87c9a59b497"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'6.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "g5VCNUhvfq0V"
      },
      "outputs": [],
      "source": [
        "from telegram import Update, ForceReply\n",
        "from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext\n",
        "\n",
        "\n",
        "def start(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Send a message when the command /start is issued.\"\"\"\n",
        "    user = update.effective_user\n",
        "    update.message.reply_markdown_v2(\n",
        "        fr'Hi {user.mention_markdown_v2()}\\!',\n",
        "        reply_markup=ForceReply(selective=True),\n",
        "    )\n",
        "\n",
        "\n",
        "def help_command(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Send a message when the command /help is issued.\"\"\"\n",
        "    update.message.reply_text('Help!')\n",
        "\n",
        "\n",
        "def run_bot(update: Update, _: CallbackContext) -> None:\n",
        "    \"\"\"Echo the user message.\"\"\"\n",
        "    replica = update.message.text\n",
        "    answer = bot(replica)\n",
        "    update.message.reply_text(answer)\n",
        "\n",
        "    print(stats)\n",
        "    print(replica)\n",
        "    print(answer)\n",
        "    print()\n",
        "    \n",
        "def main() -> None:\n",
        "    \"\"\"Start the bot.\"\"\"\n",
        "    updater = Updater(\"5527195665:AAFnReGBzkHKBqSfbMV2Zl2d14xO-ww-iIk\")\n",
        "    dispatcher = updater.dispatcher\n",
        "    dispatcher.add_handler(CommandHandler(\"start\", start))\n",
        "    dispatcher.add_handler(CommandHandler(\"help\", help_command))\n",
        "    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, run_bot))\n",
        "\n",
        "    # Start the Bot\n",
        "    updater.start_polling()\n",
        "\n",
        "    updater.idle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhjPjlnWfq0V",
        "outputId": "658b6018-ecfc-4649-af5f-89de3e2f2198"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "{'intent': 0, 'generate': 1, 'failure': 1}\n",
            "Привет\n",
            "Привет!\n",
            "\n",
            "2000\n",
            "{'intent': 0, 'generate': 2, 'failure': 1}\n",
            "Как дела\n",
            "Нормально, А почему не гуляем на свадьбе?\n",
            "\n",
            "{'intent': 1, 'generate': 2, 'failure': 1}\n",
            "Как тебя зовут?\n",
            "Привет, человек\n",
            "\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ndYeQiZfq0W"
      },
      "source": [
        "# Справка: Подбор модели, параметров и валидация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohWt8DXGfq0W"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "clf.score(X_test, y_test)\n",
        "\n",
        "scores = []\n",
        "\n",
        "#vectorizer = CountVectorizer(analyzer = 'char', ngram_range = (3,3))\n",
        "vectorizer = TfidfVectorizer(analyzer = 'char', ngram_range = (3,3))\n",
        "\n",
        "X = vectorizer.fit_transform(X_text)\n",
        "\n",
        "for i in range(10):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "    \n",
        "    clf = LinearSVC()\n",
        "    clf.fit(X_train, y_train)\n",
        "    score = clf.score(X_test, y_test)\n",
        "    scores.append(score)\n",
        "    \n",
        "print(scores)\n",
        "print(sum(scores) / len(scores))\n",
        "\n",
        "#проверим, какого максимального качества может добиться логистическая модель\n",
        "clf = LogisticRegression()\n",
        "clf.fit(X, y)\n",
        "clf.score(X, y)\n",
        "\n",
        "clf = LinearSVC()\n",
        "clf.fit(X, y)\n",
        "clf.score(X, y)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Lesson_14-Lesson_15.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}