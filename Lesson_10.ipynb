{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "736d8940",
      "metadata": {
        "id": "736d8940"
      },
      "source": [
        "# Практическое задание к уроку 10. Машинный перевод. Модель seq2seq и механизм внимания\n",
        "\n",
        "\n",
        "Разобраться с моделькой перевода как она устроена\n",
        "запустить для перевода с русского на английский (при желании можно взять другие пары языков) два варианта с вниманием и без внимания \n",
        "\n",
        "оценить качество насколько корректно переводит (для теста отобрать примеры с увеличением длины текста) (так как оценка визуальная достаточно 20-ти примеров в тестовой выборке)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65938225",
      "metadata": {
        "id": "65938225"
      },
      "source": [
        "#### Нейронный машинный перевод"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "49773a76",
      "metadata": {
        "id": "49773a76"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d19951be",
      "metadata": {
        "id": "d19951be"
      },
      "source": [
        "#### Загрузка и подготовка набора данных\n",
        "\n",
        "http://www.manythings.org/anki/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "5e990806",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e990806",
        "outputId": "cba6f3cb-8db2-4552-9e4c-952782baccb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-03 05:33:01--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14819554 (14M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  14.13M  17.7MB/s    in 0.8s    \n",
            "\n",
            "2022-08-03 05:33:02 (17.7 MB/s) - ‘rus-eng.zip’ saved [14819554/14819554]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.manythings.org/anki/rus-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "4ff04491",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ff04491",
        "outputId": "1511f7b5-e943-45fd-c045-fc260352a530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus.txt                 \n",
            "  inflating: _about.txt              \n"
          ]
        }
      ],
      "source": [
        "# !mkdir rus-eng\n",
        "# !unzip rus-eng.zip -d rus-eng/\n",
        "!unzip rus-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aa171391",
      "metadata": {
        "id": "aa171391"
      },
      "outputs": [],
      "source": [
        "# !ls /rus-eng/ -lah"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "38047d9a",
      "metadata": {
        "id": "38047d9a"
      },
      "outputs": [],
      "source": [
        "# Download the file\n",
        "# path_to_file = \"rus-eng/rus.txt\"\n",
        "path_to_file = \"rus.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9ba0d299",
      "metadata": {
        "id": "9ba0d299"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(w):\n",
        "  w = w.lower().strip()\n",
        "\n",
        "  # creating a space between a word and the punctuation following it\n",
        "  # eg: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # adding a start and an end token to the sentence\n",
        "  # so that the model know when to start and stop predicting.\n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dc330ed1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dc330ed1",
        "outputId": "332d94c0-9216-49d1-e549-195afbe230bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<start> i can't go . <end>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "preprocess_sentence(\"I can't go.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "5f335674",
      "metadata": {
        "id": "5f335674"
      },
      "outputs": [],
      "source": [
        "# 1. Remove the accents\n",
        "# 2. Clean the sentences\n",
        "# 3. Return word pairs in the format: [ENG, RUS]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ab0281a0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab0281a0",
        "outputId": "7e3af44b-83e8-4773-ed12-9da1e35507aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> go . <end>\n",
            "<start> марш ! <end>\n"
          ]
        }
      ],
      "source": [
        "en, ru = create_dataset(path_to_file, None)\n",
        "print(en[0])\n",
        "print(ru[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b67de801",
      "metadata": {
        "id": "b67de801"
      },
      "outputs": [],
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4caddf8c",
      "metadata": {
        "id": "4caddf8c"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af843ebb",
      "metadata": {
        "id": "af843ebb"
      },
      "source": [
        "#### Ограничение набора данных для ускорения обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e48af07b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e48af07b",
        "outputId": "e9f1f1c9-1e4f-46f0-910b-fbe08681534c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(444587, 444587)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(en), len(ru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "83c45dde",
      "metadata": {
        "id": "83c45dde"
      },
      "outputs": [],
      "source": [
        "# Try experimenting with the size of that dataset\n",
        "num_examples = 100000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Calculate max_length of the target tensors\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4527cb3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4527cb3d",
        "outputId": "a1679fe2-b1e2-4f85-eb1a-1ca72c5bc6f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80000 80000 20000 20000\n"
          ]
        }
      ],
      "source": [
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Show length\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "976f6edb",
      "metadata": {
        "id": "976f6edb"
      },
      "outputs": [],
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "3d49c2d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d49c2d7",
        "outputId": "1d90210c-1851-447a-a868-3564d02c10d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "53 ----> где\n",
            "20166 ----> стража\n",
            "5 ----> ?\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "102 ----> where\n",
            "21 ----> are\n",
            "12 ----> the\n",
            "4167 ----> guards\n",
            "6 ----> ?\n",
            "2 ----> <end>\n"
          ]
        }
      ],
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "114b7838",
      "metadata": {
        "id": "114b7838"
      },
      "source": [
        "#### Создаем tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "89b49114",
      "metadata": {
        "id": "89b49114"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 300\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f339afcf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f339afcf",
        "outputId": "14b576a6-8d6c-4222-8794-4c87ac654b2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 15]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "62e4ff3d",
      "metadata": {
        "id": "62e4ff3d"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=False,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    \n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "20f2a909",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20f2a909",
        "outputId": "ea656ad6-7bb0-48ab-b56b-1081274950cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "1316154f",
      "metadata": {
        "id": "1316154f"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    # fc - fully connected слой\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "67598282",
      "metadata": {
        "id": "67598282"
      },
      "outputs": [],
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "decoder_sample_x, decoder_sample_h = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5f582631",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f582631",
        "outputId": "9099f442-cee8-4c7e-e261-77c933b63f0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 7334])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "decoder_sample_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f13e8b5f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f13e8b5f",
        "outputId": "221e45cb-ec5e-44f7-aa71-ac75c7aaf7fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "decoder_sample_h.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee2117dc",
      "metadata": {
        "id": "ee2117dc"
      },
      "source": [
        "#### Определим оптимизатор и функцию потерь"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1de00b26",
      "metadata": {
        "id": "1de00b26"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "# это маскированный лосс. Мы не хотим чтобы паддиноговые нулевые токены учитывались в лоссе\n",
        "# поэтому мы получаем падинговые элементы (0) - маска\n",
        "# и зануляем там лосс\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3aa48f7",
      "metadata": {
        "id": "f3aa48f7"
      },
      "source": [
        "#### Контрольные точки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "f7f500c8",
      "metadata": {
        "id": "f7f500c8"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_nmt_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "55c9009a",
      "metadata": {
        "id": "55c9009a"
      },
      "outputs": [],
      "source": [
        "# функция для обучения модели\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "    # inp - входная последовательность (русский)\n",
        "    # target - английский\n",
        "    # enc_hidden - вектор скрытого состояния энкодера\n",
        "    loss = 0\n",
        "    \n",
        "    # берём градиенты\n",
        "    with tf.GradientTape() as tape:\n",
        "        # передаём в энкодер входную последовательность и скрытое состояние\n",
        "        # получаем выход скрытого состояния\n",
        "        enc_hidden = encoder(inp, enc_hidden)\n",
        "        \n",
        "        # присваиваем для инициализации ветора скрытого состояния в декодере\n",
        "        dec_hidden = enc_hidden\n",
        "        # добавляем тег старта для начала перевода, берём его индекс, переводим в тензор\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        # идём по таргету, по тому тексту на который хотим натренировать перевод\n",
        "        # начинаем не с нулевого токена, потому что первым стоит тег <start>\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            # мы не хотим затачиваться на предикт, прокидывая градиент будем улучшать предикт\n",
        "            predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
        "            # вычисляем лосс-функцию\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "            # using teacher forcing\n",
        "            # записываем текущий токен (таргет) на вход декодера - получается смещение\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "        # формируем все переменные по которым будет браться градиент\n",
        "        variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "        # берём градиент и применяем его к лосс-функции\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "\n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "    # возвращаем батч-лосс\n",
        "    return batch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9a496133",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a496133",
        "outputId": "b621a924-5200-4651-b79f-99b3f18e5643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 4.6522\n",
            "Epoch 1 Batch 100 Loss 2.0723\n",
            "Epoch 1 Batch 200 Loss 1.8173\n",
            "Epoch 1 Batch 300 Loss 1.6070\n",
            "Epoch 1 Batch 400 Loss 1.4451\n",
            "Epoch 1 Batch 500 Loss 1.4359\n",
            "Epoch 1 Batch 600 Loss 1.3116\n",
            "Epoch 1 Batch 700 Loss 1.2044\n",
            "Epoch 1 Batch 800 Loss 1.1546\n",
            "Epoch 1 Batch 900 Loss 0.9688\n",
            "Epoch 1 Batch 1000 Loss 0.9615\n",
            "Epoch 1 Batch 1100 Loss 1.0036\n",
            "Epoch 1 Batch 1200 Loss 0.9061\n",
            "Epoch 1 Loss 1.3901\n",
            "Time taken for 1 epoch 2854.260957956314 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.9179\n",
            "Epoch 2 Batch 100 Loss 0.8135\n",
            "Epoch 2 Batch 200 Loss 0.7139\n",
            "Epoch 2 Batch 300 Loss 0.7082\n",
            "Epoch 2 Batch 400 Loss 0.7407\n",
            "Epoch 2 Batch 500 Loss 0.6255\n",
            "Epoch 2 Batch 600 Loss 0.6512\n",
            "Epoch 2 Batch 700 Loss 0.5918\n",
            "Epoch 2 Batch 800 Loss 0.5751\n",
            "Epoch 2 Batch 900 Loss 0.6031\n",
            "Epoch 2 Batch 1000 Loss 0.5820\n",
            "Epoch 2 Batch 1100 Loss 0.5232\n",
            "Epoch 2 Batch 1200 Loss 0.5810\n",
            "Epoch 2 Loss 0.6771\n",
            "Time taken for 1 epoch 2850.745584011078 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.3784\n",
            "Epoch 3 Batch 100 Loss 0.3681\n",
            "Epoch 3 Batch 200 Loss 0.4312\n",
            "Epoch 3 Batch 300 Loss 0.3894\n",
            "Epoch 3 Batch 400 Loss 0.4103\n",
            "Epoch 3 Batch 500 Loss 0.4253\n",
            "Epoch 3 Batch 600 Loss 0.4065\n",
            "Epoch 3 Batch 700 Loss 0.3241\n",
            "Epoch 3 Batch 800 Loss 0.4120\n",
            "Epoch 3 Batch 900 Loss 0.5078\n",
            "Epoch 3 Batch 1000 Loss 0.3186\n",
            "Epoch 3 Batch 1100 Loss 0.3075\n",
            "Epoch 3 Batch 1200 Loss 0.3545\n",
            "Epoch 3 Loss 0.3699\n",
            "Time taken for 1 epoch 2822.867032289505 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.2528\n",
            "Epoch 4 Batch 100 Loss 0.1816\n",
            "Epoch 4 Batch 200 Loss 0.2478\n",
            "Epoch 4 Batch 300 Loss 0.2308\n",
            "Epoch 4 Batch 400 Loss 0.2064\n",
            "Epoch 4 Batch 500 Loss 0.1970\n",
            "Epoch 4 Batch 600 Loss 0.1971\n",
            "Epoch 4 Batch 700 Loss 0.2355\n",
            "Epoch 4 Batch 800 Loss 0.2548\n",
            "Epoch 4 Batch 900 Loss 0.2341\n",
            "Epoch 4 Batch 1000 Loss 0.2336\n",
            "Epoch 4 Batch 1100 Loss 0.2646\n",
            "Epoch 4 Batch 1200 Loss 0.2288\n",
            "Epoch 4 Loss 0.2218\n",
            "Time taken for 1 epoch 2945.1870000362396 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1263\n",
            "Epoch 5 Batch 100 Loss 0.1258\n",
            "Epoch 5 Batch 200 Loss 0.1533\n",
            "Epoch 5 Batch 300 Loss 0.1583\n",
            "Epoch 5 Batch 400 Loss 0.1361\n",
            "Epoch 5 Batch 500 Loss 0.1206\n",
            "Epoch 5 Batch 600 Loss 0.1339\n",
            "Epoch 5 Batch 700 Loss 0.1301\n",
            "Epoch 5 Batch 800 Loss 0.1276\n",
            "Epoch 5 Batch 900 Loss 0.1781\n",
            "Epoch 5 Batch 1000 Loss 0.1901\n",
            "Epoch 5 Batch 1100 Loss 0.1295\n",
            "Epoch 5 Batch 1200 Loss 0.2071\n",
            "Epoch 5 Loss 0.1519\n",
            "Time taken for 1 epoch 2932.2042684555054 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # saving (checkpoint) the model every 2 epochs\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c9e396c7",
      "metadata": {
        "id": "c9e396c7"
      },
      "outputs": [],
      "source": [
        "# функция для оценки перевода\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    # препроцессинг предложения\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "    # переводим каждый токен в индекс\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    # переводим в тензор\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    # посылаем в энкодер\n",
        "    enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        # т.к. у нас нет таргета - передаём предсказание на следующий шаг\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "        # останавливаемся если встречаем токен конца\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f8939570",
      "metadata": {
        "id": "f8939570"
      },
      "outputs": [],
      "source": [
        "def translate(sentence):\n",
        "  result, sentence = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fef27371",
      "metadata": {
        "id": "fef27371"
      },
      "source": [
        "#### Восстановление контрольной точки, и тестирование\n",
        "\n",
        "Так как нет механизма внимания, при увеличении длины предложения качество падает."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "952fe00f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "952fe00f",
        "outputId": "3fc5e7c4-ff6b-4e5b-e82b-30e0585d3ace"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe860e2dc50>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# restoring the latest checkpoint in checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "7b5034a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b5034a3",
        "outputId": "d7644b8d-f708-48ca-fcb5-0271640b0391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> как хочется чтобы учиться было легко <end>\n",
            "Predicted translation: how do to . . . . . . . . \n"
          ]
        }
      ],
      "source": [
        "translate('Как хочется чтобы учиться было легко')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "71ecd538",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71ecd538",
        "outputId": "05e9f707-4f9f-4d6e-d3a1-f66c5d41b630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> в этом году снова без отпуска осталась <end>\n",
            "Predicted translation: come water in water . . . . . . . \n"
          ]
        }
      ],
      "source": [
        "translate('В этом году снова без отпуска осталась')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "0816a204",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0816a204",
        "outputId": "09f30105-e365-435e-f243-3b9bec3b92d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> бывает ли лучше чем сейчас ? <end>\n",
            "Predicted translation: is else come here ? ? ? ? ? ? ? \n"
          ]
        }
      ],
      "source": [
        "translate('Бывает ли лучше чем сейчас?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "5fb60e5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fb60e5a",
        "outputId": "f9d02d90-353c-42ca-87c0-65502dae42cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> прекрасное далеко ? <end>\n",
            "Predicted translation: are the ? ? ? ? ? ? ? ? ? \n"
          ]
        }
      ],
      "source": [
        "translate('Прекрасное далеко?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4460ed67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4460ed67",
        "outputId": "a27189cc-6f3a-45f3-a0b9-51f56bbfbccb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> как прекрасен этот мир ! посмотри и улыбнись ! <end>\n",
            "Predicted translation: how this this ! ! ! ! ! ! ! ! \n"
          ]
        }
      ],
      "source": [
        "translate('Как прекрасен этот мир! Посмотри и улыбнись!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5e7ab660",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e7ab660",
        "outputId": "331d5f7b-0e95-4438-b969-3a51acc10725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> чтоб я так жил ! <end>\n",
            "Predicted translation: i i with . . . . . . . . \n"
          ]
        }
      ],
      "source": [
        "translate('Чтоб я так жил!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "f43b863e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f43b863e",
        "outputId": "f9becb43-2fbc-4584-f594-073c5c6ddb5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> и дн м , и ночью кот все ходит по цепи . <end>\n",
            "Predicted translation: come come , now . . . . . . . \n"
          ]
        }
      ],
      "source": [
        "translate('И днём, и ночью кот все ходит по цепи.') # ученый, кругом - не распознает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "be37786e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be37786e",
        "outputId": "29516ed1-0a44-4f0f-fb4f-5de1003f725c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> золотая на груди . <end>\n",
            "Predicted translation: the onto easily . . . . . . . . \n"
          ]
        }
      ],
      "source": [
        "translate('золотая на груди.') # Ночевала, тучка, утеса, великана - не распознает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "1333cda7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1333cda7",
        "outputId": "b40fb1bf-4606-4fa6-9c7a-86c8e6e7376e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> поднимается медленно в гору . . . <end>\n",
            "Predicted translation: the christmas in . . . . . . . . \n"
          ]
        }
      ],
      "source": [
        "translate('поднимается медленно в гору...') # Гляжу - не распознает"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "5841e6c8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5841e6c8",
        "outputId": "42e65772-e15b-48fd-edcc-7785dc2d6bde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> он себя заставил и лучше не мог . <end>\n",
            "Predicted translation: he he useful wrong . . . . . . . \n"
          ]
        }
      ],
      "source": [
        "translate('Он себя заставил и лучше не мог.') # уважать, выдумать - не распознает"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2975f730",
      "metadata": {
        "id": "2975f730"
      },
      "source": [
        "Не стал продолжать примеры из-за отвратительного перевода. Скорее всего из-за маленькой величины эпох. Маленькое количество эпох выбрал в целях экономии времени на обучение."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "name": "Lesson_10.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}